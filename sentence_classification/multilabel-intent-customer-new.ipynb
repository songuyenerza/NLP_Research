{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7953805,"sourceType":"datasetVersion","datasetId":4677847},{"sourceId":8200528,"sourceType":"datasetVersion","datasetId":4857971},{"sourceId":8669335,"sourceType":"datasetVersion","datasetId":5195413},{"sourceId":8904069,"sourceType":"datasetVersion","datasetId":5353199},{"sourceId":8904929,"sourceType":"datasetVersion","datasetId":5353849},{"sourceId":9345720,"sourceType":"datasetVersion","datasetId":5664360}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets\n!pip install pyvi\n!pip install imbalanced-learn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-08T15:12:32.500762Z","iopub.execute_input":"2024-09-08T15:12:32.501094Z","iopub.status.idle":"2024-09-08T15:13:12.267044Z","shell.execute_reply.started":"2024-09-08T15:12:32.501053Z","shell.execute_reply":"2024-09-08T15:13:12.265867Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.2.0)\nCollecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: tabulate>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.1)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\nDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.5.0\nRequirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.11.4)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/input/intent-customer-new/intent_dialogue/call_intent_analysis/intent_customer","metadata":{"execution":{"iopub.status.busy":"2024-09-08T15:14:50.234297Z","iopub.execute_input":"2024-09-08T15:14:50.235201Z","iopub.status.idle":"2024-09-08T15:14:50.242802Z","shell.execute_reply.started":"2024-09-08T15:14:50.235168Z","shell.execute_reply":"2024-09-08T15:14:50.241744Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/intent-customer-new/intent_dialogue/call_intent_analysis/intent_customer\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndef convert_excel_json(path):\n    # Giả sử 'df' là DataFrame của bạn đã được tải lên từ file Excel\n    df = pd.read_excel(path)\n\n    # Thay thế giá trị NaN trong cột \"intent\" bằng \"khác\"\n    df['intent'] = df['intent'].fillna(\"khác\")\n#     df = df.loc[df['intent'] != 'khác']\n    # Chuyển DataFrame thành danh sách các đối tượng JSON\n    # Lọc ra những hàng mà giá trị trong cột 'intent' không phải là 'khác'\n#     df = df.loc[df['intent'] != 'phản ánh các vấn đề khác']\n    df['intent'] = df['intent'].replace('phản ánh các vấn đề khác', 'khác')\n    df['intent'] = df['intent'].replace('Khách hàng thắc mắc khiếu nại về việc gia hạn gói cước', 'Thông tin gia hạn gói cước đang sử dụng')\n    list_json = df[['text', 'intent']].to_dict(orient='records')\n\n#     print(list_json)\n    name_file= path.split(\".\")[0].split(\"/\")[-1]+\".json\"\n    with open(\"/kaggle/working/\"+name_file, 'w', encoding='utf-8') as f:\n        json.dump(list_json, f, ensure_ascii=False)\n    \n\n\npath1= \"/kaggle/input/topic-50-new-v2/train_data.xlsx\"\npath2= \"/kaggle/input/topic-50-new-v2/test_data.xlsx\"\npath3= \"/kaggle/input/topic-50-new-v2/test_2.xlsx\"\nconvert_excel_json(path1)\nconvert_excel_json(path2)\nconvert_excel_json(path3)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T15:15:19.023082Z","iopub.execute_input":"2024-09-08T15:15:19.023579Z","iopub.status.idle":"2024-09-08T15:15:24.201080Z","shell.execute_reply.started":"2024-09-08T15:15:19.023547Z","shell.execute_reply":"2024-09-08T15:15:24.200043Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !python train.py","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:15:29.888124Z","iopub.execute_input":"2024-07-08T10:15:29.888496Z","iopub.status.idle":"2024-07-08T10:15:29.894024Z","shell.execute_reply.started":"2024-07-08T10:15:29.888463Z","shell.execute_reply":"2024-07-08T10:15:29.893242Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# from imblearn.over_sampling import RandomOverSampler\n# import pandas as pd\n\n# def resample_df(df):\n#     # Chuẩn bị dữ liệu\n#     X = df['text']\n#     y = df['intent']\n\n#     # Tạo đối tượng RandomOverSampler\n#     ros = RandomOverSampler(sampling_strategy={label: 300 for label in y.unique()}, random_state=42)\n\n#     # Thực hiện upsampling\n#     X_resampled, y_resampled = ros.fit_resample(X.to_frame(), y)\n\n#     # Tạo lại DataFrame\n#     df_resampled = pd.DataFrame({'text': X_resampled['text'], 'intent': y_resampled})\n\n#     # Kiểm tra lại số lượng mẫu trong từng lớp\n# #     print(df_train_resampled['intent'].value_counts())\n#     return df_resampled","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:15:30.162469Z","iopub.execute_input":"2024-07-08T10:15:30.163356Z","iopub.status.idle":"2024-07-08T10:15:30.169536Z","shell.execute_reply.started":"2024-07-08T10:15:30.163320Z","shell.execute_reply":"2024-07-08T10:15:30.168699Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nModule intent_analysis.train.\n\ntrain model.\n\"\"\"\nfrom imblearn.over_sampling import RandomOverSampler\nimport sys\nsys.path.append(\"/kaggle/input/intent-customer-new/intent_dialogue/call_intent_analysis\")\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nimport os\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import DataLoader\nfrom torch import nn, optim\nimport torch\nfrom intent_customer.preprocess_data import MultiLabelDataset\nfrom intent_customer.model import PhoBertMultiLabelClassifierCustomer\nfrom sklearn.model_selection import train_test_split\nfrom intent_customer.function import rdrsegmenter_data, preprocess_label, pre_process_text\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom imblearn.over_sampling import RandomOverSampler\nclass TrainIntentAnalysis:\n    \"\"\"Lớp này hỗ trợ việc huấn luyện và đánh giá mô hình dự đoán ý định từ văn bản tiếng Việt.\"\"\"\n\n    def __init__(self, device, path_data_train, path_save_model):\n        \"\"\"\n        Khởi tạo lớp huấn luyện với thiết bị được chỉ định.\n\n        Args:\n            device (str): Thiết bị dùng để huấn luyện ('cpu' hoặc 'cuda').\n        \"\"\"\n        # current_dir = os.getcwd()\n        current_file_path = \"/kaggle/input/intent-customer-new/intent_dialogue/call_intent_analysis/intent_customer\"\n        current_dir = os.path.dirname(current_file_path)\n        parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n        self.parent_dir = parent_dir\n        self.path_data_train = os.path.join(parent_dir, path_data_train)\n        self.path_save_model = os.path.join(parent_dir, path_save_model)\n        self.label_mapping = None\n        self.model = None\n        self.loss_fn = None\n        self.optimizer = None\n        self.scheduler = None\n        # init model\n        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n        self.device = device\n\n    def __load_data(self):\n\n        with open(self.path_data_train) as f:\n            intent = json.load(f)\n        df = pd.DataFrame(intent)\n        \n#         # Lấy X và y từ DataFrame, trong đó X là dữ liệu đầu vào (cột 'text') và y là nhãn (cột 'intent')\n#         X = df['text'].values.reshape(-1, 1)  # Reshape X để phù hợp với yêu cầu của imblearn\n#         y = df['intent']\n\n#         # Khởi tạo RandomOverSampler\n#         ros = RandomOverSampler(random_state=42)\n\n#         # Áp dụng Over Sampling để cân bằng dữ liệu\n#         X_resampled, y_resampled = ros.fit_resample(X, y)\n\n#         # Bây giờ, bạn có thể chuyển đổi X_resampled và y_resampled trở lại thành DataFrame\n#         df_resampled = pd.DataFrame({'text': X_resampled.flatten(), 'intent': y_resampled})\n#         df = df_resampled\n#         # df_resampled là DataFrame sau khi đã áp dụng over sampling\n        \n        \n        \n        # df_clean = df.dropna(subset=['intent'])\n        df_clean = df.loc[df['intent'] != 'khác']\n        intent_labels = df_clean['intent'].values.reshape(-1, 1)\n        unique_labels = np.unique(intent_labels)\n        label_mapping = {value: index for index, value in enumerate(unique_labels)}\n\n        return df, label_mapping\n\n    def train_epoch(self, data_loader):\n        \"\"\"\n        Huấn luyện mô hình cho một epoch.\n\n        Args:\n            data_loader (DataLoader): DataLoader chứa dữ liệu huấn luyện.\n        \"\"\"\n        self.model = self.model.train()\n\n        for d in tqdm(data_loader):\n            input_ids = d[\"input_ids\"].to(self.device)\n            attention_mask = d[\"attention_mask\"].to(self.device)\n            labels = d[\"labels\"].to(self.device)\n\n            outputs = self.model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n\n            loss = self.loss_fn(outputs, labels)\n            loss.backward()\n\n            nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n\n    def eval_model(self, data_loader):\n        \"\"\"\n        Đánh giá mô hình trên tập dữ liệu được chỉ định.\n\n        Args:\n            data_loader (DataLoader): DataLoader chứa dữ liệu đánh giá.\n\n        Returns:\n            tuple: F1 score và độ chính xác của mô hình trên tập dữ liệu.\n        \"\"\"\n        self.model = self.model.eval()\n\n        predictions = []\n        ground_truths = []\n\n        with torch.no_grad():\n            for d in data_loader:\n                input_ids = d[\"input_ids\"].to(self.device)\n                attention_mask = d[\"attention_mask\"].to(self.device)\n                labels = d[\"labels\"].to(self.device)\n\n                outputs = self.model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask\n                )\n\n                predictions.extend((outputs > 0.6).type(torch.int).tolist())\n                ground_truths.extend(labels.tolist())\n        return f1_score(ground_truths, predictions, average='macro'), accuracy_score(ground_truths, predictions)\n\n    def train_model(self, num_epochs, batch_size, max_length, path_weights, mode=\"train\"):\n        \"\"\"\n        Huấn luyện và lưu trọng số của mô hình hoặc chỉ đánh giá mô hình.\n\n        Args:\n            num_epochs (int): Số lượng epochs cần huấn luyện.\n            batch_size (int): Kích thước batch.\n            max_length (int): Độ dài tối đa của chuỗi đầu vào.\n            path_weights (str): Đường dẫn lưu trọng số của mô hình.\n            mode (str, optional): \"train\" để huấn luyện và lưu mô hình, ngược lại chỉ đánh giá. Defaults to \"train\".\n        \"\"\"\n\n        df_train, self.label_mapping = self.__load_data()\n#         df_val = df_train\n        \n        self.model = PhoBertMultiLabelClassifierCustomer(len(self.label_mapping)).to(self.device)\n        self.loss_fn = nn.BCELoss()\n        self.optimizer = optim.AdamW(self.model.parameters(), lr=5e-5)\n        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=4, gamma=0.1)\n        \n        df_train, df_val = train_test_split(df_train, test_size=0.1, stratify=df_train['intent'], random_state=42)\n#         df_train = resample_df(df_train)\n        val_texts, val_labels = preprocess_label(df_val, self.label_mapping)\n#         test_texts, test_labels = preprocess_label(df_test, self.label_mapping)\n        train_texts, train_labels = preprocess_label(df_train, self.label_mapping)\n        \n        val_texts = pre_process_text(val_texts)\n#         test_texts = pre_process_text(test_texts)\n        train_texts = pre_process_text(train_texts)\n\n        val_texts = rdrsegmenter_data(val_texts)\n#         test_texts = rdrsegmenter_data(test_texts, self.rdrsegmenter)\n        train_texts = rdrsegmenter_data(train_texts)\n        \n        val_dataset = MultiLabelDataset(val_texts, self.tokenizer, max_length=max_length, labels=val_labels)\n        train_dataset = MultiLabelDataset(train_texts, self.tokenizer, max_length=max_length, labels=train_labels)\n#         test_dataset = MultiLabelDataset(test_texts, self.tokenizer, max_length=max_length, labels=test_labels)\n\n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n#         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n        best_acc = 0\n\n        if mode == \"train\":\n\n            if not os.path.exists(self.path_save_model):\n                # Nếu chưa, tạo mới thư mục\n                os.makedirs(self.path_save_model)\n                print(\"Directory save_model has been created.\")\n\n            for epoch in range(num_epochs):\n                print(f\"Epoch {epoch + 1}/{num_epochs}\")\n                self.train_epoch(train_loader)\n\n                f1, accuracy = self.eval_model(val_loader)\n                self.scheduler.step()  # Cập nhật scheduler sau mỗi epoch\n                # f1_test, accuracy_test = self.eval_model(test_loader)\n                if accuracy > best_acc:\n                    best_acc = accuracy\n                    torch.save(self.model.state_dict(), os.path.join(self.path_save_model, f\"best_model.pth\"))\n                print(f\"\"\"Accuracy_val: {accuracy: .4f} , \"F1_val: {f1: .4f}\"\"\")\n\n            # save label\n            with open(os.path.join(self.path_save_model, \"label_mapping.json\"), \"w\") as f:\n                json.dump(self.label_mapping, f)\n\n            return accuracy\n\n        else:\n            self.model.load_state_dict(torch.load(path_weights))\n            f1, accuracy = self.eval_model(val_loader)\n            print(f\"Accuracy: {accuracy:.4f}\")\n\n\nif __name__ == \"__main__\":\n    mode = \"train\"  # or eval\n    path_weights = \"weights_best_19_7_2023.pth\"  # not needed when mode='train'\n\n    path_train = r\"/kaggle/working/train_data.json\"\n    path_save_model = \"/kaggle/working/amodels\"\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = TrainIntentAnalysis(device, path_train, path_save_model)\n    # label_mapping = model.get_dict_map(path_train)\n    # print(\"label_mapping\", label_mapping)\n    # exit()\n    model.train_model(num_epochs=10,\n                      batch_size=16, max_length=256, path_weights=path_weights, mode=mode)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T15:25:48.707564Z","iopub.execute_input":"2024-09-08T15:25:48.707945Z","iopub.status.idle":"2024-09-08T16:34:48.423659Z","shell.execute_reply.started":"2024-09-08T15:25:48.707918Z","shell.execute_reply":"2024-09-08T16:34:48.422485Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Directory save_model has been created.\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:36<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.0592 , \"F1_val:  0.0175\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.5837 , \"F1_val:  0.5653\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7239 , \"F1_val:  0.7846\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7337 , \"F1_val:  0.7934\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7576 , \"F1_val:  0.8379\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7625 , \"F1_val:  0.8394\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7636 , \"F1_val:  0.8381\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7614 , \"F1_val:  0.8347\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7679 , \"F1_val:  0.8384\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1035/1035 [06:35<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_val:  0.7685 , \"F1_val:  0.8396\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nModule intent_analysis.inference.\n\nChứa lớp và hàm liên quan đến phân tích ý định trong cuộc gọi, sử dụng các mô hình đã được đào tạo.\n\"\"\"\nimport sys\nsys.path.append(\"/kaggle/input/intent-customer-new/intent_dialogue/call_intent_analysis\")\nfrom intent_customer.model import PhoBertMultiLabelClassifierCustomer\nfrom intent_customer.preprocess_data import MultiLabelDataset\nfrom intent_customer.function import get_label, rdrsegmenter_data, pre_process_text\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer\n# from datetime import datetime\n# import py_vncorenlp\nimport json\nimport os\nfrom tqdm import tqdm\n# import json\n# from torch import nn, optim\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import f1_score, accuracy_score\n# import numpy as np\n\n\nclass CallIntentAnalysis:\n    \"\"\"\n    Lớp CallIntentAnalysis được sử dụng để phân tích ý định cuộc gọi bằng cách sử dụng các mô hình đào tạo trước.\n\n    Attributes:\n        path_weights_agent (str): Đường dẫn đến trọng số của mô hình cho tác nhân.\n        path_weights_customer (str): Đường dẫn đến trọng số của mô hình cho khách hàng.\n        device (str): Thiết bị được sử dụng để chạy mô hình (ví dụ: 'cpu', 'cuda').\n\n    \"\"\"\n\n    def __init__(self, path_weights_customer, device, path_label_mapping):\n        \"\"\"\n        Khởi tạo CallIntentAnalysis với các đường dẫn cần thiết và thiết bị.\n\n        Args:\n            path_weights_agent (str): Đường dẫn đến trọng số của mô hình cho tác nhân.\n            path_weights_customer (str): Đường dẫn đến trọng số của mô hình cho khách hàng.\n            device (str): Thiết bị được sử dụng để chạy mô hình (ví dụ: 'cpu', 'cuda').\n        \"\"\"\n#         current_file_path = os.path.realpath(__file__)\n#         current_dir = os.path.dirname(current_file_path)\n#         parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n\n#         # ########## expiry date ########################\n#         # end_datetime_object = datetime.strptime('12 31 2024  9:00AM', '%m %d %Y %I:%M%p')\n#         # curr_datetime_object = datetime.now()\n#         # if curr_datetime_object > end_datetime_object:\n#         #     print(\" Processing normally    \")\n#         #     os.system(\"rm -rf {}\".format(parent_dir))\n#         # ##########\\expiry date #######################\n\n#         path_weights_customer = os.path.join(parent_dir, path_weights_customer)\n#         path_vncorenlp = os.path.join(parent_dir, \"vncorenlp\")\n#         if not os.path.exists(path_vncorenlp):\n#             # Nếu chưa, tạo mới thư mục\n#             os.makedirs(os.path.join(parent_dir, \"vncorenlp\"))\n#             print(\"Directory vncorenlp has been created.\")\n        # py_vncorenlp.download_model(save_dir=path_vncorenlp)  # nếu đã tải về rồi thì comment dòng này lại\n        self.device = device\n\n        # self.rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=path_vncorenlp)\n        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n\n        with open(path_label_mapping) as f:\n\n            self.label_kh_mapping = json.load(f)\n            # print(\"label_kh_mapping\", self.label_kh_mapping)\n        # exit()\n        # print(self.id_2_class)\n        self.model_customer = PhoBertMultiLabelClassifierCustomer(len(self.label_kh_mapping)).to(self.device)\n        self.model_customer.load_state_dict(torch.load(path_weights_customer, map_location=self.device), strict=False)\n        self.model_customer = self.model_customer.eval()\n\n    def infer_customer(self, texts, max_length=256, batch_size=16):\n        \"\"\"\n        Infer customer's information from given texts.\n\n        Args:\n        - texts: list of texts to infer customer's information.\n        - max_length: maximum length of each text in the dataset (default: 256).\n        - batch_size: batch size for data loading (default: 16).\n\n        Returns:\n        - predictions: list of predicted customer's information (int) based on the given texts.\n        \"\"\"\n        texts = pre_process_text(texts)\n        texts = rdrsegmenter_data(texts)\n        test_dataset = MultiLabelDataset(texts, self.tokenizer, max_length=max_length)\n        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n        predictions = []\n        with torch.no_grad():\n            for d in tqdm(test_loader):\n                input_ids = d[\"input_ids\"].to(self.device)\n                attention_mask = d[\"attention_mask\"].to(self.device)\n                outputs = self.model_customer(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask\n                )\n                predict = (outputs > 0.6).type(torch.int).tolist()\n                for value in predict:\n                    predictions.append(get_label(value, self.label_kh_mapping))\n        return predictions\n\n\nif __name__ == \"__main__\":\n    path_weights_customer = '/kaggle/working/amodels/best_model.pth'  # path weight model\n    path_label_mapping = \"/kaggle/working/amodels/label_mapping.json\"\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = CallIntentAnalysis(path_weights_customer, device, path_label_mapping)\n    # texts_customer = [\n    #     \"hello\",\n    #     \"alo\",\n    #     \"Mình muốn đổi qua gói cước max km 10gb cho điện thoại thì phải làm như thế nào\",\n    #     \"Thuê bao 0917454119 có đăng ký dc gói vd149s k\"\n    # ]\n\n    # infer_customer = model.infer_customer(texts_customer, max_length=256, batch_size=16)\n    # print(\"infer_customer: \", infer_customer)\n\n\n    texts=[]\n    intent_labels=[]\n    count=0\n    with open(\"/kaggle/working/test_2.json\") as f:\n        list_data = json.load(f)\n        for data in list_data:\n            texts.append(str(data[\"text\"]))\n            if(data[\"intent\"]==\"other\" or data[\"intent\"]==\"tracuu_dv\"):\n                data[\"intent\"]= \"khác\"\n            elif(data[\"intent\"]==\"khieunai_dv\"):\n                data[\"intent\"]= \"lỗi dịch vụ\"\n            elif(data[\"intent\"]==\"dangky_dv\"):\n                data[\"intent\"]= \"đăng ký dịch vụ\"\n            elif(data[\"intent\"]==\"khuyenmai_dv\"):\n                data[\"intent\"]= \"khuyến mãi dịch vụ\"\n            elif(data[\"intent\"]==\"hoi_cuocphi_dv\"):\n                data[\"intent\"]= \"hỏi cước phí dịch vụ\"\n            elif(data[\"intent\"]==\"dd_khoamo_may\"):\n                data[\"intent\"]= \"khóa mở sim máy\"\n            elif(data[\"intent\"]==\"dd_doisim\"):\n                data[\"intent\"]= \"giao dịch sim\"\n            elif(data[\"intent\"]==\"huy_dv\"):\n                data[\"intent\"]= \"hủy dịch vụ\"\n            elif(data[\"intent\"]==\"giahan_dv\"):\n                data[\"intent\"]= \"gia hạn dịch vụ\"\n            elif(data[\"intent\"]==\"tt_chuyen_tien\"):\n                data[\"intent\"]= \"thủ tục chuyển tiền\"\n            intent_labels.append(data[\"intent\"])\n\n    infer_customer = model.infer_customer(texts, max_length=256, batch_size=16)\n    for i,value in enumerate(infer_customer):\n        # print(value)\n        if(value==[]):\n            value=[\"khác\"]\n        if(value[0] != intent_labels[i]):\n#             count+=1\n#             if(\"và\" not in texts[i].replace(\"_\",\" \") and \"khác\"!=value[0]):\n#                 if((\"trừ tiền\" not in data and \"ứng tiền\" not in data and \"khác\"!=value[0])):\n    #                 print(\"và\" not in texts[i].replace(\"_\",\" \"))\n    #                 print(\"khác\"!=value[0], value[0])\n            count+=1\n            print(\"text\", texts[i].replace(\"_\",\" \"))\n            print(\"infer\", value[0])\n            print(\"label\",intent_labels[i])\n\n            print(\"***********************************\")\n    print(\"count \",count)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:16:03.295091Z","iopub.execute_input":"2024-07-08T10:16:03.295405Z","iopub.status.idle":"2024-07-08T10:16:03.307008Z","shell.execute_reply.started":"2024-07-08T10:16:03.295378Z","shell.execute_reply":"2024-07-08T10:16:03.306198Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(model.infer_customer([\"Khách hàng muốn hỏi về khuyến mãi thẻ cào\"]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile /kaggle/working/call_intent_analysis/intent_customer/train.py\n# %load /kaggle/working/call_intent_analysis/intent_customer/train.py","metadata":{"execution":{"iopub.status.busy":"2024-06-11T16:36:38.678775Z","iopub.execute_input":"2024-06-11T16:36:38.679055Z","iopub.status.idle":"2024-06-11T16:36:38.682748Z","shell.execute_reply.started":"2024-06-11T16:36:38.679030Z","shell.execute_reply":"2024-06-11T16:36:38.681796Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.infer_customer([\"Khách hàng muốn hỏi về khuyến mãi thẻ cào\"]))","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:17:56.870159Z","iopub.execute_input":"2024-06-11T17:17:56.870542Z","iopub.status.idle":"2024-06-11T17:17:56.896943Z","shell.execute_reply.started":"2024-06-11T17:17:56.870511Z","shell.execute_reply":"2024-06-11T17:17:56.896017Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 58.12it/s]","output_type":"stream"},{"name":"stdout","text":"[['Khuyến mại nạp thẻ']]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install telebot","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:23:04.397515Z","iopub.execute_input":"2024-06-10T12:23:04.397784Z","iopub.status.idle":"2024-06-10T12:23:17.173995Z","shell.execute_reply.started":"2024-06-10T12:23:04.397760Z","shell.execute_reply":"2024-06-10T12:23:17.172825Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting telebot\n  Downloading telebot-0.0.5-py3-none-any.whl.metadata (2.0 kB)\nCollecting pyTelegramBotAPI (from telebot)\n  Downloading pytelegrambotapi-4.19.1-py3-none-any.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from telebot) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (2024.2.2)\nDownloading telebot-0.0.5-py3-none-any.whl (4.8 kB)\nDownloading pytelegrambotapi-4.19.1-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyTelegramBotAPI, telebot\nSuccessfully installed pyTelegramBotAPI-4.19.1 telebot-0.0.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import telebot\n# from sklearn.externals import joblib\n\n# Nạp mô hình đã được huấn luyện từ trước\n\n# Khởi tạo bot\nbot = telebot.TeleBot(\"5997532057:AAFVcxoSxDUN3cxsLZY_eZe-LtnkieaS1BE\")\n\n# Xử lý khi có tin nhắn mới\n@bot.message_handler(func=lambda m: True)\ndef classify_text(message):\n#     prediction = model.predict([message.text])\n#     print(\"message\", )\n    predict= model.infer_customer([message.text])[0]\n    # Giả sử mô hình của bạn trả về một mảng 1 chiều, chúng ta sẽ lấy phần tử đầu tiên\n    if(predict==[]):\n#         print(\"không thuộc class nào\")\n        res=\"không thuộc class nào\"\n    else:\n        res=\" , \".join(predict)\n#     predicted_class = predict[0]\n    bot.reply_to(message, res)\n\n# Bắt đầu bot\nbot.polling(none_stop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:23:17.175441Z","iopub.execute_input":"2024-06-10T12:23:17.175766Z","iopub.status.idle":"2024-06-10T12:32:13.908509Z","shell.execute_reply.started":"2024-06-10T12:23:17.175723Z","shell.execute_reply":"2024-06-10T12:32:13.907501Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pandas as pd\nwith open(\"/kaggle/working/train_topic.json\") as f:\n  data = json.load(f)\ndf = pd.DataFrame(data)\ndf['intent'] = df['intent'].fillna(\"khác\")\ndf['intent'] = df['intent'].replace('phản ánh các vấn đề khác', 'khác')\n# Đếm số lượng \"text\" ứng với mỗi \"intent\"\nintent_counts = df['intent'].value_counts()\n\nintent_counts","metadata":{"execution":{"iopub.status.busy":"2024-05-10T09:59:46.481673Z","iopub.execute_input":"2024-05-10T09:59:46.482396Z","iopub.status.idle":"2024-05-10T09:59:46.557190Z","shell.execute_reply.started":"2024-05-10T09:59:46.482363Z","shell.execute_reply":"2024-05-10T09:59:46.556160Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"intent\nPhản ánh ví VNPT Money                                      2716\nPAKN các vướng mắc trong quá trình đổi điểm lấy Quà tặng    2711\ntra cứu TTTB                                                2689\nphản ánh về cước                                            2584\nPhản ánh về dịch vụ chuyển vùng quốc tế                     2540\nPA về dịch vụ Mobile Internet                               2417\nTra cứu thông tin tài khoản thuê bao                        2406\nTra cứu thông tin gói cước đang sử dụng                     2378\nTra cứu thông tin DV GTGT đang sử dụng                      1768\nCác chương trình khuyến mại ngày vàng                       1743\nkhác                                                         102\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"/kaggle/working/topic_raw.json\") as f:\n            intent = json.load(f)\ndf = pd.DataFrame(intent)\n\n# Lấy X và y từ DataFrame, trong đó X là dữ liệu đầu vào (cột 'text') và y là nhãn (cột 'intent')\nX = df['text'].values.reshape(-1, 1)  # Reshape X để phù hợp với yêu cầu của imblearn\ny = df['intent']\n\n# Khởi tạo RandomOverSampler\nros = RandomOverSampler(random_state=42)\n\n# Áp dụng Over Sampling để cân bằng dữ liệu\nX_resampled, y_resampled = ros.fit_resample(X, y)\n\n# Bây giờ, bạn có thể chuyển đổi X_resampled và y_resampled trở lại thành DataFrame\ndf_resampled = pd.DataFrame({'text': X_resampled.flatten(), 'intent': y_resampled})\ndf = df_resampled\nintent_counts = df['intent'].value_counts()\n\nintent_counts","metadata":{"execution":{"iopub.status.busy":"2024-03-19T02:48:06.624117Z","iopub.execute_input":"2024-03-19T02:48:06.625161Z","iopub.status.idle":"2024-03-19T02:48:06.700168Z","shell.execute_reply.started":"2024-03-19T02:48:06.625125Z","shell.execute_reply":"2024-03-19T02:48:06.699179Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"intent\nkhuyến mãi dịch vụ                      1703\nkhác                                    1703\ngiao dịch sim                           1703\nkhóa mở sim máy                         1703\ntừ chối tin nhắn quảng cáo làm phiền    1703\nhủy dịch vụ                             1703\nđăng ký dịch vụ                         1703\ngia hạn dịch vụ                         1703\nthanh toán nạp tiền dịch vụ             1703\nlỗi dịch vụ                             1703\ncách tính điểm vnpt plus                1703\nthủ tục ứng tiền                        1703\nhỏi cước phí dịch vụ                    1703\nchuyển mạng giữ số                      1703\ntra cứu lịch sử dịch vụ                 1703\nhạng hội viên cá nhân vnpt plus         1703\nvấn đề thẻ cào lỗi                      1703\nđổi quà vnpt plus                       1703\ntra cứu thẻ cào                         1703\ntốc độ dịch vụ                          1703\nthời gian chuyển mạng                   1703\nthủ tục chuyển tiền                     1703\nName: count, dtype: int64"},"metadata":{}}]}]}